{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic tables:\n",
      "movie_financials\n",
      "directors\n",
      "actors\n",
      "movie_actor_bridge\n",
      "awards\n",
      "streaming\n",
      "user_ratings\n",
      "country_data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Load the base IMDB table\n",
    "base_df = pd.read_csv(r\"D:\\uni\\AdvancedTopics\\project2\\PossibileDB\\IMDB\\IMDB_Ver_0.csv\")\n",
    "\n",
    "# Initialize Faker for realistic fake data\n",
    "fake = Faker()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "## Table 1: Movie Financials (could join on Series_Title)\n",
    "num_movies = len(base_df)\n",
    "movie_financials = pd.DataFrame({\n",
    "    'Series_Title': base_df['Series_Title'],\n",
    "    'Production_Budget': [random.randint(1, 200) * 1000000 for _ in range(num_movies)],\n",
    "    'Box_Office_Gross': lambda x: [int(b * random.uniform(0.5, 10.0) for b in x['Production_Budget'])],\n",
    "    'Profitability_Ratio': lambda x: x['Box_Office_Gross'] / x['Production_Budget'],\n",
    "    'Primary_Production_Company': [fake.company() for _ in range(num_movies)],\n",
    "    'Release_Season': [random.choice(['Spring', 'Summer', 'Fall', 'Winter']) for _ in range(num_movies)]\n",
    "})\n",
    "\n",
    "## Table 2: Director Information (could join on Series_Title)\n",
    "directors = pd.DataFrame({\n",
    "    'Series_Title': base_df['Series_Title'],\n",
    "    'Director_Name': [fake.name() for _ in range(num_movies)],\n",
    "    'Director_Gender': [random.choice(['Male', 'Female', 'Non-binary']) for _ in range(num_movies)],\n",
    "    'Director_Nationality': [fake.country() for _ in range(num_movies)],\n",
    "    'Director_Birth_Year': [random.randint(1940, 1990) for _ in range(num_movies)],\n",
    "    'Director_Awards': [random.randint(0, 20) for _ in range(num_movies)]\n",
    "})\n",
    "\n",
    "## Table 3: Actor Information (many-to-many relationship, needs bridge table)\n",
    "actors = pd.DataFrame({\n",
    "    'Actor_ID': range(1, 201),\n",
    "    'Actor_Name': [fake.name() for _ in range(200)],\n",
    "    'Actor_Gender': [random.choice(['Male', 'Female']) for _ in range(200)],\n",
    "    'Actor_Nationality': [fake.country() for _ in range(200)],\n",
    "    'Actor_Debut_Year': [random.randint(1970, 2020) for _ in range(200)],\n",
    "    'Actor_Awards': [random.randint(0, 15) for _ in range(200)]\n",
    "})\n",
    "\n",
    "# Bridge table for movie-actor relationships\n",
    "movie_actor_bridge = pd.DataFrame({\n",
    "    'Series_Title': random.choices(base_df['Series_Title'], k=500),\n",
    "    'Actor_ID': random.choices(actors['Actor_ID'], k=500),\n",
    "    'Role_Type': random.choices(['Lead', 'Supporting', 'Cameo'], weights=[0.5, 0.45, 0.05], k=500),\n",
    "    'Salary': [random.randint(50000, 5000000) for _ in range(500)]\n",
    "}).drop_duplicates()\n",
    "\n",
    "## Table 4: Awards Information (could join on Series_Title)\n",
    "awards = pd.DataFrame({\n",
    "    'Series_Title': random.choices(base_df['Series_Title'], k=150),\n",
    "    'Award_Name': random.choices(['Oscar', 'Golden Globe', 'BAFTA', 'Cannes', 'Sundance'], k=150),\n",
    "    'Award_Category': random.choices(['Best Picture', 'Best Director', 'Best Actor', 'Best Actress', \n",
    "                                     'Best Screenplay', 'Best Cinematography'], k=150),\n",
    "    'Award_Year': [random.randint(2000, 2023) for _ in range(150)],\n",
    "    'Won': random.choices([True, False], weights=[0.3, 0.7], k=150)\n",
    "}).drop_duplicates()\n",
    "\n",
    "## Table 5: Streaming Availability (could join on Series_Title)\n",
    "streaming = pd.DataFrame({\n",
    "    'Series_Title': base_df['Series_Title'],\n",
    "    'Available_On': [random.choice(['Netflix', 'Amazon Prime', 'HBO Max', 'Disney+', 'Hulu', 'None']) \n",
    "                     for _ in range(num_movies)],\n",
    "    'Subscription_Required': [random.choice([True, False]) for _ in range(num_movies)],\n",
    "    'Release_Date': [fake.date_between(start_date='-10y', end_date='today') for _ in range(num_movies)],\n",
    "    'Price': [round(random.uniform(0, 19.99), 2) if random.random() > 0.7 else 0 for _ in range(num_movies)]\n",
    "})\n",
    "\n",
    "## Table 6: User Ratings (could join on Series_Title)\n",
    "user_ratings = pd.DataFrame({\n",
    "    'Series_Title': random.choices(base_df['Series_Title'], k=1000),\n",
    "    'User_ID': [fake.uuid4() for _ in range(1000)],\n",
    "    'User_Rating': [round(random.uniform(1, 10), 1) for _ in range(1000)],\n",
    "    'Review_Date': [fake.date_between(start_date='-5y', end_date='today') for _ in range(1000)],\n",
    "    'Review_Text': [fake.text(max_nb_chars=200) for _ in range(1000)]\n",
    "})\n",
    "\n",
    "## Table 7: Country-Specific Data (could join on Series_Title)\n",
    "country_data = pd.DataFrame({\n",
    "    'Series_Title': random.choices(base_df['Series_Title'], k=300),\n",
    "    'Country': [fake.country() for _ in range(300)],\n",
    "    'Release_Date': [fake.date_between(start_date='-30y', end_date='today') for _ in range(300)],\n",
    "    'Localized_Title': [fake.catch_phrase() if random.random() > 0.7 else None for _ in range(300)],\n",
    "    'Censorship_Rating': random.choices(['G', 'PG', 'PG-13', 'R', 'NC-17', 'Unrated'], k=300)\n",
    "}).drop_duplicates()\n",
    "\n",
    "# Save all tables to CSV files\n",
    "tables = {\n",
    "    'movie_financials': movie_financials,\n",
    "    'directors': directors,\n",
    "    'actors': actors,\n",
    "    'movie_actor_bridge': movie_actor_bridge,\n",
    "    'awards': awards,\n",
    "    'streaming': streaming,\n",
    "    'user_ratings': user_ratings,\n",
    "    'country_data': country_data\n",
    "}\n",
    "\n",
    "for name, table in tables.items():\n",
    "    table.to_csv(f'{name}.csv', index=False)\n",
    "\n",
    "print(\"Generated synthetic tables:\")\n",
    "print(\"\\n\".join(tables.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize ground truth dataframe\n",
    "ground_truth = pd.DataFrame(columns=[\n",
    "    'version_name',\n",
    "    'version_number',\n",
    "    'base_table',\n",
    "    'joined_tables',\n",
    "    'join_type',\n",
    "    'missing_data_introduced',\n",
    "    'missing_data_percentage',\n",
    "    'description',\n",
    "    'rows_in_output',\n",
    "    'columns_in_output',\n",
    "    'created_at'\n",
    "])\n",
    "\n",
    "# Function to record version metadata\n",
    "def record_version(name, number, base, joins, join_type, missing, missing_pct, desc, df):\n",
    "    new_record = pd.DataFrame([{\n",
    "        'version_name': name,\n",
    "        'version_number': number,\n",
    "        'base_table': base,\n",
    "        'joined_tables': joins,\n",
    "        'join_type': join_type,\n",
    "        'missing_data_introduced': missing,\n",
    "        'missing_data_percentage': missing_pct,\n",
    "        'description': desc,\n",
    "        'rows_in_output': len(df),\n",
    "        'columns_in_output': len(df.columns),\n",
    "        'created_at': datetime.now()\n",
    "    }])\n",
    "    return new_record\n",
    "# Function to introduce missing values\n",
    "def add_missing_values(df, pct=0.1, exclude_cols=['Series_Title', 'Released_Year']):\n",
    "    df_missing = df.copy()\n",
    "    for col in df_missing.columns:\n",
    "        if col not in exclude_cols:\n",
    "            mask = np.random.random(len(df_missing)) < pct\n",
    "            df_missing.loc[mask, col] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "# Load all tables\n",
    "base_df = pd.read_csv('sinteticDB/IMDB/IMDB_Base.csv')\n",
    "movie_financials = pd.read_csv('sinteticDB/IMDB/externalTables/movie_financials.csv')\n",
    "directors = pd.read_csv('sinteticDB/IMDB/externalTables/directors.csv')\n",
    "streaming = pd.read_csv('sinteticDB/IMDB/externalTables/streaming.csv')\n",
    "country_data = pd.read_csv('sinteticDB/IMDB/externalTables/country_data.csv')\n",
    "awards = pd.read_csv('sinteticDB/IMDB/externalTables/awards.csv')\n",
    "user_ratings = pd.read_csv('sinteticDB/IMDB/externalTables/user_ratings.csv')\n",
    "movie_actor_bridge = pd.read_csv('sinteticDB/IMDB/externalTables/movie_actor_bridge.csv')\n",
    "actors = pd.read_csv('sinteticDB/IMDB/externalTables/actors.csv')\n",
    "\n",
    "# Define missing value percentages to simulate\n",
    "missing_percentages = [0.05, 0.15]  # 5% and 15% missing data\n",
    "\n",
    "# Version counter\n",
    "version_counter = 1\n",
    "\n",
    "# Original versions without missing data\n",
    "versions = [\n",
    "    # Version 1 left: Base + Financials\n",
    "    ('imdb_with_financials_l', \n",
    "     lambda: pd.merge(base_df, movie_financials, on='Series_Title', how='left'),\n",
    "     \"Base table with financial information added\",\"left\"),\n",
    "\n",
    "     # Version 1 inner: Base + Financials\n",
    "    ('imdb_with_financials_i', \n",
    "     lambda: pd.merge(base_df, movie_financials, on='Series_Title', how='inner'),\n",
    "     \"Base table with financial information added\",\"inner\"),\n",
    "\n",
    "     # Version 1 right: Base + Financials\n",
    "    ('imdb_with_financials_r', \n",
    "     lambda: pd.merge(base_df, movie_financials, on='Series_Title', how='right'),\n",
    "     \"Base table with financial information added\",\"right\"),\n",
    "    \n",
    "    # Version 2 left: Base + Directors\n",
    "    ('imdb_with_directors_l', \n",
    "     lambda: pd.merge(base_df, directors, on='Series_Title', how='left'),\n",
    "     \"Base table with director information added\",\"left\"),\n",
    "\n",
    "    # Version 2 inner: Base + Directors\n",
    "    ('imdb_with_directors_i', \n",
    "     lambda: pd.merge(base_df, directors, on='Series_Title', how='inner'),\n",
    "     \"Base table with director information added\",\"inner\"),\n",
    "    \n",
    "    # Version 2 right: Base + Directors\n",
    "    ('imdb_with_directors_r', \n",
    "     lambda: pd.merge(base_df, directors, on='Series_Title', how='right'),\n",
    "     \"Base table with director information added\",\"right\"),\n",
    "\n",
    "    # Version 3 left: Base + Streaming\n",
    "    ('imdb_with_streaming_l', \n",
    "     lambda: pd.merge(base_df, streaming, on='Series_Title', how='left'),\n",
    "     \"Base table with streaming availability added\",\"left\"),\n",
    "\n",
    "    # Version 3 inner: Base + Streaming\n",
    "    ('imdb_with_streaming_i', \n",
    "     lambda: pd.merge(base_df, streaming, on='Series_Title', how='inner'),\n",
    "     \"Base table with streaming availability added\",\"inner\"),\n",
    "\n",
    "    # Version 3 right: Base + Streaming\n",
    "    ('imdb_with_streaming_r', \n",
    "     lambda: pd.merge(base_df, streaming, on='Series_Title', how='right'),\n",
    "     \"Base table with streaming availability added\",\"right\"),\n",
    "    \n",
    "    # Version 4 left: Base + Country Data\n",
    "    ('imdb_with_country_data_l', \n",
    "     lambda: pd.merge(base_df, country_data, on='Series_Title', how='left'),\n",
    "     \"Base table with country-specific release data added\",\"left\"),\n",
    "\n",
    "    # Version 4 inner: Base + Country Data\n",
    "    ('imdb_with_country_data_i', \n",
    "     lambda: pd.merge(base_df, country_data, on='Series_Title', how='inner'),\n",
    "     \"Base table with country-specific release data added\",\"inner\"),\n",
    "\n",
    "    # Version 4 right: Base + Country Data\n",
    "    ('imdb_with_country_data_r', \n",
    "     lambda: pd.merge(base_df, country_data, on='Series_Title', how='right'),\n",
    "     \"Base table with country-specific release data added\",\"right\"),\n",
    "    \n",
    "    # Version 5 left: Base + Awards\n",
    "    ('imdb_with_awards_l', \n",
    "     lambda: pd.merge(base_df, awards, on='Series_Title', how='left'),\n",
    "     \"Base table with awards information (may have duplicate movie rows)\",\"left\"),\n",
    "\n",
    "    # Version 5 inner: Base + Awards\n",
    "    ('imdb_with_awards_i', \n",
    "     lambda: pd.merge(base_df, awards, on='Series_Title', how='inner'),\n",
    "     \"Base table with awards information (may have duplicate movie rows)\",\"inner\"),\n",
    "\n",
    "    # Version 5 right: Base + Awards\n",
    "    ('imdb_with_awards_r', \n",
    "     lambda: pd.merge(base_df, awards, on='Series_Title', how='right'),\n",
    "     \"Base table with awards information (may have duplicate movie rows)\",\"right\"),\n",
    "    \n",
    "    \n",
    "    # Version 6: Base + Lead Actors\n",
    "    ('imdb_with_lead_actor', \n",
    "     lambda: pd.merge(\n",
    "         base_df,\n",
    "         pd.merge(\n",
    "             movie_actor_bridge[movie_actor_bridge['Role_Type'] == 'Lead'].drop_duplicates('Series_Title', keep='first'),\n",
    "             actors,\n",
    "             on='Actor_ID'\n",
    "         )[['Series_Title', 'Actor_Name']],\n",
    "         on='Series_Title', how='left'),\n",
    "     \"Base table with name of lead actor added\",\"left\"),\n",
    "    \n",
    "    # Version 7: Base + Financials + Directors\n",
    "    ('imdb_with_financials_and_directors', \n",
    "     lambda: pd.merge(\n",
    "         pd.merge(base_df, movie_financials, on='Series_Title', how='left'),\n",
    "         directors,\n",
    "         on='Series_Title', how='left'),\n",
    "     \"Base table with both financial and director information\",\"left\"),\n",
    "    \n",
    "    # Version 10: Comprehensive (will be handled separately)\n",
    "]\n",
    "\n",
    "# Create original versions and missing data variants\n",
    "for version_name, join_func, desc, join_type in versions:\n",
    "    # Create original version\n",
    "    df = join_func()\n",
    "    df.to_csv(f'{version_name}.csv', index=False)\n",
    "    ground_truth = pd.concat([\n",
    "        ground_truth,\n",
    "        record_version(\n",
    "            version_name, version_counter,\n",
    "            'IMDB_Base.csv', version_name.split('_with_')[1],\n",
    "            join_type, False, 0,\n",
    "            desc, df\n",
    "        )\n",
    "    ], ignore_index=True)\n",
    "    version_counter += 1\n",
    "    \n",
    "    # Create versions with missing values\n",
    "    for pct in missing_percentages:\n",
    "        missing_version_name = f\"{version_name}_missing_{int(pct*100)}pct\"\n",
    "        df_missing = add_missing_values(df, pct)\n",
    "        df_missing.to_csv(f'{missing_version_name}.csv', index=False)\n",
    "        ground_truth = pd.concat([\n",
    "            ground_truth,\n",
    "            record_version(\n",
    "                missing_version_name, version_counter,\n",
    "                'IMDB_Base.csv', version_name.split('_with_')[1],\n",
    "                'left', True, pct,\n",
    "                f\"{desc} with {int(pct*100)}% missing values\",\n",
    "                df_missing\n",
    "            )\n",
    "        ], ignore_index=True)\n",
    "        version_counter += 1\n",
    "\n",
    "# Special case for comprehensive version\n",
    "comp_df = pd.merge(base_df, movie_financials, on='Series_Title', how='left')\n",
    "comp_df = pd.merge(comp_df, streaming, on='Series_Title', how='left')\n",
    "comp_df = pd.merge(comp_df, \n",
    "                  user_ratings.groupby('Series_Title')['User_Rating'].mean().reset_index(), \n",
    "                  on='Series_Title', how='left')\n",
    "comp_df.to_csv('imdb_comprehensive.csv', index=False)\n",
    "ground_truth = pd.concat([\n",
    "    ground_truth,\n",
    "    record_version(\n",
    "        'imdb_comprehensive', version_counter,\n",
    "        'IMDB_Base.csv', 'movie_financials + streaming + user_ratings',\n",
    "        'left', False, 0,\n",
    "        \"Base table with financials, streaming, and ratings combined\",\n",
    "        comp_df\n",
    "    )\n",
    "], ignore_index=True)\n",
    "version_counter += 1\n",
    "\n",
    "# Create missing versions for comprehensive\n",
    "for pct in missing_percentages:\n",
    "    missing_version_name = f\"imdb_comprehensive_missing_{int(pct*100)}pct\"\n",
    "    comp_missing = add_missing_values(comp_df, pct)\n",
    "    comp_missing.to_csv(f'{missing_version_name}.csv', index=False)\n",
    "    ground_truth = pd.concat([\n",
    "        ground_truth,\n",
    "        record_version(\n",
    "            missing_version_name, version_counter,\n",
    "            'IMDB_Base.csv', 'movie_financials + streaming + user_ratings',\n",
    "            'left', True, pct,\n",
    "            f\"Comprehensive version with {int(pct*100)}% missing values\",\n",
    "            comp_missing\n",
    "        )\n",
    "    ], ignore_index=True)\n",
    "    version_counter += 1\n",
    "\n",
    "# Save ground truth\n",
    "ground_truth.to_csv('ground_truth_versions.csv', index=False)\n",
    "\n",
    "print(f\"Created {len(ground_truth)} total versions\")\n",
    "print(f\"Saved ground truth to: ground_truth_versions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version_name</th>\n",
       "      <th>version_number</th>\n",
       "      <th>base_table</th>\n",
       "      <th>joined_tables</th>\n",
       "      <th>join_type</th>\n",
       "      <th>missing_data_introduced</th>\n",
       "      <th>missing_data_percentage</th>\n",
       "      <th>description</th>\n",
       "      <th>rows_in_output</th>\n",
       "      <th>columns_in_output</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdb_with_financials_l</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB_Base.csv</td>\n",
       "      <td>financials_l</td>\n",
       "      <td>left</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Base table with financial information added</td>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-04-07 19:00:56.962902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdb_with_financials_l_missing_5pct</td>\n",
       "      <td>2</td>\n",
       "      <td>IMDB_Base.csv</td>\n",
       "      <td>financials_l</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Base table with financial information added wi...</td>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-04-07 19:00:56.972452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb_with_financials_l_missing_15pct</td>\n",
       "      <td>3</td>\n",
       "      <td>IMDB_Base.csv</td>\n",
       "      <td>financials_l</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Base table with financial information added wi...</td>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-04-07 19:00:56.981968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb_with_financials_i</td>\n",
       "      <td>4</td>\n",
       "      <td>IMDB_Base.csv</td>\n",
       "      <td>financials_i</td>\n",
       "      <td>inner</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Base table with financial information added</td>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-04-07 19:00:56.995157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imdb_with_financials_i_missing_5pct</td>\n",
       "      <td>5</td>\n",
       "      <td>IMDB_Base.csv</td>\n",
       "      <td>financials_i</td>\n",
       "      <td>left</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Base table with financial information added wi...</td>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-04-07 19:00:57.006195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           version_name  version_number     base_table  \\\n",
       "0                imdb_with_financials_l               1  IMDB_Base.csv   \n",
       "1   imdb_with_financials_l_missing_5pct               2  IMDB_Base.csv   \n",
       "2  imdb_with_financials_l_missing_15pct               3  IMDB_Base.csv   \n",
       "3                imdb_with_financials_i               4  IMDB_Base.csv   \n",
       "4   imdb_with_financials_i_missing_5pct               5  IMDB_Base.csv   \n",
       "\n",
       "  joined_tables join_type  missing_data_introduced  missing_data_percentage  \\\n",
       "0  financials_l      left                    False                     0.00   \n",
       "1  financials_l      left                     True                     0.05   \n",
       "2  financials_l      left                     True                     0.15   \n",
       "3  financials_i     inner                    False                     0.00   \n",
       "4  financials_i      left                     True                     0.05   \n",
       "\n",
       "                                         description  rows_in_output  \\\n",
       "0        Base table with financial information added             800   \n",
       "1  Base table with financial information added wi...             800   \n",
       "2  Base table with financial information added wi...             800   \n",
       "3        Base table with financial information added             800   \n",
       "4  Base table with financial information added wi...             800   \n",
       "\n",
       "   columns_in_output                  created_at  \n",
       "0                 11  2025-04-07 19:00:56.962902  \n",
       "1                 11  2025-04-07 19:00:56.972452  \n",
       "2                 11  2025-04-07 19:00:56.981968  \n",
       "3                 11  2025-04-07 19:00:56.995157  \n",
       "4                 11  2025-04-07 19:00:57.006195  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(r\"sinteticDB\\IMDB\\ground_truth_versions.csv\").head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIRD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
